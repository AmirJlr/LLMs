{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50392aad-0609-432a-bdee-b4b5266e1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee28970-e12e-4863-9ce1-2bd601484daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=12R898xmbgA0e41b6PGBVM0trb8wfn7lY\n",
      "From (redirected): https://drive.google.com/uc?id=12R898xmbgA0e41b6PGBVM0trb8wfn7lY&confirm=t&uuid=807e1b28-d6ca-40fd-b11d-bc0fea8648ae\n",
      "To: /workspace/peft-english_to_persian_gemma2.zip\n",
      "100%|█████████████████████████████████████████| 206M/206M [00:02<00:00, 101MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=12R898xmbgA0e41b6PGBVM0trb8wfn7lY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e38606-c6e9-42cd-955c-ce9a0e5b9fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  peft-english_to_persian_gemma2.zip\n",
      "  inflating: peft-english_to_persian_gemma2/README.md  \n",
      "  inflating: peft-english_to_persian_gemma2/adapter_model.safetensors  \n",
      "  inflating: peft-english_to_persian_gemma2/adapter_config.json  \n",
      "  inflating: peft-english_to_persian_gemma2/tokenizer_config.json  \n",
      "  inflating: peft-english_to_persian_gemma2/special_tokens_map.json  \n",
      "  inflating: peft-english_to_persian_gemma2/tokenizer.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip peft-english_to_persian_gemma2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdefb13a-aaa2-4da6-af20-3b947a861f83",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c857a833-3246-478d-99cf-d1a2ddd4120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed8348a-b021-4563-9ba3-50172cdc9907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a275d308e648cc9946dadd5996f907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "peft_model_path = \"./peft-english_to_persian_gemma2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_path)\n",
    "\n",
    "bnbConfig = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-9b-it\",\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnbConfig\n",
    ")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(base_model, peft_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83de22d-bbd2-467d-a176-226b7c6803f3",
   "metadata": {},
   "source": [
    "# Reload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba3b1408-23e3-4b69-9fff-74264391f392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_text(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        texts = f.readlines()\n",
    "    texts = [line.strip() for line in texts if line.strip()]\n",
    "    return texts\n",
    "\n",
    "\n",
    "source_texts = load_text('ak-test-1k.en')\n",
    "reference_texts = load_text('ak-test-1k.fa')\n",
    "\n",
    "len(source_texts), len(reference_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5041ae6-5755-4bc7-9bff-63027d100130",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_texts = source_texts[:100]\n",
    "reference_texts = reference_texts[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bebbf1-6b3c-489b-b4f6-e2e1510a91c1",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48465790-62e7-45d6-b146-bb8843eb81ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c1105169db463eaa5b676aa0646eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing translations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomputed BLEU Score: 0.1034\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import evaluate\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "source_texts_list = []\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(source_texts)), desc=\"Processing translations\"):\n",
    "        source_text = source_texts[i]\n",
    "        reference_text = reference_texts[i]\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Translate the following English text to Persian:\n",
    "        English: {source_text}\n",
    "\n",
    "        Persian translation:\"\"\"\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH\n",
    "        ).to(device)\n",
    "\n",
    "        input_token_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "        full_output_ids = peft_model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=100,\n",
    "            do_sample=False  # deterministic\n",
    "        )[0]\n",
    "\n",
    "        output_only_ids = full_output_ids[input_token_length:]\n",
    "        cleaned_output = tokenizer.decode(\n",
    "            output_only_ids,\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        prediction_text = cleaned_output.strip()\n",
    "\n",
    "        predictions.append(prediction_text)\n",
    "        references.append([reference_text])\n",
    "        source_texts_list.append(source_text)\n",
    "        if len(references)==500:\n",
    "            break\n",
    "\n",
    "\n",
    "results = bleu.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(f\"Recomputed BLEU Score: {results['bleu']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5eb69ee-cf4e-423a-9115-0c4d2933c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source (English)</th>\n",
       "      <th>Reference (Persian)</th>\n",
       "      <th>Prediction (Gemma)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politics without the imagination is bureaucrac...</td>\n",
       "      <td>سياست بدون تخیل، چيزي نيست به جز كاغذ بازي، ول...</td>\n",
       "      <td>سیاست بدون تخیل بوروکراسی است ، اما تخیل هرگز ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The shantytowns built on the outskirts of Lima...</td>\n",
       "      <td>زاغه‌هايي كه در حومه‌هاي شهر ليما، پايتخت پرو ...</td>\n",
       "      <td>حومه های ساخته شده در حومه لیمای پرو ، محصول ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Populated by underemployed laborers from the c...</td>\n",
       "      <td>اين شهرك‌ها مملوند از كارگراني بي كار که از لي...</td>\n",
       "      <td>توسط کارگران بیکار از شهر و کشاورزان آواره از ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a number of these shantytowns were originally ...</td>\n",
       "      <td>بسياري از اين زاغه‌ها در دهه هفتاد به وجود آمد...</td>\n",
       "      <td>تعدادی از این شهرک های شantytown در ابتدا در د...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In 2002, one of these shantytowns, named Venta...</td>\n",
       "      <td>در سال 2002 ، يكي از اين زاغه‌ها به نام \"ونتان...</td>\n",
       "      <td>در سال 2002 ، یکی از این محله های فقیرنشین به ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The surrounding landscape is desert.</td>\n",
       "      <td>پيرامون اين شهر چيزي به جز صحرا نيست</td>\n",
       "      <td>چشم انداز اطراف صحرا است .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To move a mountain on this landscape, Francis ...</td>\n",
       "      <td>براي جا به جا كردن آن \"فرانسيس آليس\"، به هر يك...</td>\n",
       "      <td>برای جابجایی کوهی در این منظره ، فرانسیس الیس ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>or as he described it in an interview publishe...</td>\n",
       "      <td>يا به گفته خود آليس در مصاحبه‌اش با مجله آرت ف...</td>\n",
       "      <td>یا همان طور که او در مصاحبه ای که در آرت فوروم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This human comb pushed a certain quantity of s...</td>\n",
       "      <td>اين شانه انساني توانست مقدار زيادي شن را جابجا...</td>\n",
       "      <td>این شانه انسانی مقدار معینی از شن را به یک فاص...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This combination of poetic vagueness and preci...</td>\n",
       "      <td>اين تركيب مبهم شاعرانه همراه با دستورعملي دقيق...</td>\n",
       "      <td>این ترکیب از ابهام شاعرانه و دستورالعمل دقیق د...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Source (English)  \\\n",
       "0  Politics without the imagination is bureaucrac...   \n",
       "1  The shantytowns built on the outskirts of Lima...   \n",
       "2  Populated by underemployed laborers from the c...   \n",
       "3  a number of these shantytowns were originally ...   \n",
       "4  In 2002, one of these shantytowns, named Venta...   \n",
       "5               The surrounding landscape is desert.   \n",
       "6  To move a mountain on this landscape, Francis ...   \n",
       "7  or as he described it in an interview publishe...   \n",
       "8  This human comb pushed a certain quantity of s...   \n",
       "9  This combination of poetic vagueness and preci...   \n",
       "\n",
       "                                 Reference (Persian)  \\\n",
       "0  سياست بدون تخیل، چيزي نيست به جز كاغذ بازي، ول...   \n",
       "1  زاغه‌هايي كه در حومه‌هاي شهر ليما، پايتخت پرو ...   \n",
       "2  اين شهرك‌ها مملوند از كارگراني بي كار که از لي...   \n",
       "3  بسياري از اين زاغه‌ها در دهه هفتاد به وجود آمد...   \n",
       "4  در سال 2002 ، يكي از اين زاغه‌ها به نام \"ونتان...   \n",
       "5               پيرامون اين شهر چيزي به جز صحرا نيست   \n",
       "6  براي جا به جا كردن آن \"فرانسيس آليس\"، به هر يك...   \n",
       "7  يا به گفته خود آليس در مصاحبه‌اش با مجله آرت ف...   \n",
       "8  اين شانه انساني توانست مقدار زيادي شن را جابجا...   \n",
       "9  اين تركيب مبهم شاعرانه همراه با دستورعملي دقيق...   \n",
       "\n",
       "                                  Prediction (Gemma)  \n",
       "0  سیاست بدون تخیل بوروکراسی است ، اما تخیل هرگز ...  \n",
       "1  حومه های ساخته شده در حومه لیمای پرو ، محصول ج...  \n",
       "2  توسط کارگران بیکار از شهر و کشاورزان آواره از ...  \n",
       "3  تعدادی از این شهرک های شantytown در ابتدا در د...  \n",
       "4  در سال 2002 ، یکی از این محله های فقیرنشین به ...  \n",
       "5                         چشم انداز اطراف صحرا است .  \n",
       "6  برای جابجایی کوهی در این منظره ، فرانسیس الیس ...  \n",
       "7  یا همان طور که او در مصاحبه ای که در آرت فوروم...  \n",
       "8  این شانه انسانی مقدار معینی از شن را به یک فاص...  \n",
       "9  این ترکیب از ابهام شاعرانه و دستورالعمل دقیق د...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samples = pd.DataFrame({\n",
    "    'Source (English)': source_texts_list[:10],\n",
    "    'Reference (Persian)': [ref[0] for ref in references[:10]],\n",
    "    'Prediction (Gemma)': predictions[:10]\n",
    "})\n",
    "\n",
    "df_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87fc0bf8-fd55-4f17-b993-5430f26050d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_english_to_persian(\n",
    "    english_text: str,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    max_input_length: int = 512, # Max length for input + prompt\n",
    "    max_new_tokens: int = 100   # Max tokens to generate for the translation\n",
    "):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Translate the following English text to Persian:\n",
    "English: {english_text}\n",
    "\n",
    "Persian translation:\"\"\"\n",
    "\n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,          # Padding might not be strictly necessary for single input, but good practice\n",
    "        truncation=True,\n",
    "        max_length=max_input_length\n",
    "    ).to(device)\n",
    "\n",
    "    input_token_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Generate translation with no sampling (deterministic output)\n",
    "    with torch.no_grad():\n",
    "        full_output_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id # Important for generation to know when padding starts if padding=True\n",
    "        )[0] # Get the first (and only) sequence from the batch\n",
    "\n",
    "    # Extract only the generated tokens (remove the input prompt tokens)\n",
    "    output_only_ids = full_output_ids[input_token_length:]    # Decode the generated tokens into text\n",
    "    translated_text = tokenizer.decode(\n",
    "        output_only_ids,        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return translated_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "927bf2fa-3859-42a9-9c02-08a8840d350f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'یادگیری ماشین یک حوزه از هوش مصنوعی است .**'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "english_sentence = \"Machine learning is a field of artificial intelligence.\"\n",
    "translate_english_to_persian(english_sentence, peft_model, tokenizer, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
